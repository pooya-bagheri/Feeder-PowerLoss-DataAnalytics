{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: Pooya Bagheri*               <b>Under Construction</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Machine Learning (ML) Objective\n",
    "\n",
    "From now on, our objective is to create statistical learning (or machine learning) models to estimate feeder power loss from voltages at a specific instant. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training and Test Data Sets\n",
    "\n",
    "The common practice is to randomly split the available data to training and test sets. However, we know our data here is coming from simulations that were generated by random instant load profiles. So, we can go ahead and pick few days of simulation results as Training and another few days for the Test, and it will be automatically a random split. Additionally, the other advantage of keeping time-continuous data is allowing for better visualizations.\n",
    "\n",
    "Hence, for all the tests of ML models in this project we choose the last 5 of the available 30 days data. For training the linear models here, we grab data of the first 10 days For now we are not loading the whole 25 left days' data to avoid memory limitation problem. Later, we will take advantage of total data through iterative data streaming.\n",
    " \n",
    "Ok, let's create our training and test sets accordingly. Similar to previous [step](Step1-DataExploration.ipynb), we have to use SQL query and also pivoting for the voltage data. In order to avoid repetitive coding, we define a class called *MLinputData* for loading data for generic period of simulation days. (Please refer back to [previous step](Step1-DataExploration.ipynb) for more information, if the below procedure of SQL query and dataframe pivoting of is not clear to your)\n",
    "\n",
    "Definition of this class is loaded below. Please note that for any future data loading we will rather directly import and use this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-c45f89f9cbd0>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-c45f89f9cbd0>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    where Instants.Day>=%d and Instants.Day<=%d''', % (FromDay,ToDay),con=DB)\u001b[0m\n\u001b[1;37m                                                                             \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %load LoadingDataClass.py\n",
    "# @author: Pooya Bagheri\n",
    "import os \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "# a class is defined for loading data and covering the SQL and pivoting procedure:\n",
    "class MLinputData:\n",
    "    def __init__(self,FromDay,ToDay):\n",
    "        RawVoltages=pd.read_sql_query('''\n",
    "        select Instants.InstantID,Voltages.NodeID,Voltages.Vmag\n",
    "        from Instants join Voltages on Instants.InstantID=Voltages.InstantID\n",
    "        where Instants.Day>=%d and Instants.Day<=%d''' % (FromDay,ToDay),con=DB)\n",
    "        Voltages=RawVoltages.pivot(index='InstantID', columns='NodeID', values='Vmag')\n",
    "        self.x=Voltages.values\n",
    "        Ploss=pd.read_sql_query('''\n",
    "        select Losses.Ploss\n",
    "        from Instants join Losses on Instants.InstantID=Losses.InstantID\n",
    "        where Instants.Day>=%d and Instants.Day<=%d''', % (FromDay,ToDay),con=DB)\n",
    "        self.y=Ploss.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "train=MLinputData(1,5) # Loading Training sets (first 5 days)\n",
    "test=MLinputData(26,30) # Loading Test sets (last 5 of 30 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
